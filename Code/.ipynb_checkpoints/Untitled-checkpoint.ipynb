{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/cluster/tufts/lamontagnelab/abirnb01/GCIMS/Abby_paper/queries/query_results/combined_csvs/water_withdrawals_source.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-87a8c2bade61>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mspath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'/cluster/tufts/lamontagnelab/abirnb01/GCIMS/Abby_paper/queries/query_results/pickled_data/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mqueryName\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'water_withdrawals_source'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mww\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mqueryName\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.csv'\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#read CSV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;31m#split up surface water and groundwater\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mww_gw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mww\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mww\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubresource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'groundwater'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#just groundwater\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\gcam0\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 912\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\gcam0\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    575\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 577\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    578\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\gcam0\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1405\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\gcam0\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\"b\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1661\u001b[1;33m             self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\gcam0\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/cluster/tufts/lamontagnelab/abirnb01/GCIMS/Abby_paper/queries/query_results/combined_csvs/water_withdrawals_source.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "\n",
    "#load in CSV for water withdrawals (separated by sufrace water or groundwater)\n",
    "fpath = '/cluster/tufts/lamontagnelab/abirnb01/GCIMS/Abby_paper/queries/query_results/combined_csvs/'\n",
    "spath = '/cluster/tufts/lamontagnelab/abirnb01/GCIMS/Abby_paper/queries/query_results/pickled_data/'\n",
    "queryName = 'water_withdrawals_source'\n",
    "ww = pd.read_csv(fpath+queryName+'.csv')  #read CSV\n",
    "#split up surface water and groundwater\n",
    "ww_gw = ww[ww.subresource.str.contains('groundwater')] #just groundwater\n",
    "ww_sw = ww[ww.subresource.str.contains('runoff')] #just surface water\n",
    "\n",
    "#filter to remove column for region (just care about basin) and to sum up different groundwater grades\n",
    "ww = ww.groupby(['scenario','Units','resource','year'])['value'].sum().reset_index()\n",
    "ww_gw = ww_gw.groupby(['scenario','Units','resource','year'])['value'].sum().reset_index()\n",
    "ww_sw = ww_sw.groupby(['scenario','Units','resource','year'])['value'].sum().reset_index()\n",
    "#these lines of code are used to clean up the basin name column (originally \"resource\") in the 3 dataframes\n",
    "ww[['basin','ww']] = ww['resource'].str.split('_water withdrawals',n=2,expand=True)\n",
    "ww = ww.drop(['ww','resource'],axis=1)\n",
    "ww_gw[['basin','ww']] = ww_gw['resource'].str.split('_water withdrawals',n=2,expand=True)\n",
    "ww_gw = ww_gw.drop(['ww','resource'],axis=1)\n",
    "ww_sw[['basin','ww']] = ww_sw['resource'].str.split('_water withdrawals',n=2,expand=True)\n",
    "ww_sw = ww_sw.drop(['ww','resource'],axis=1)\n",
    "#save the cleaned up data as pickles:\n",
    "ww.to_pickle(spath+'ww')\n",
    "ww_gw.to_pickle(spath+'ww_gw')\n",
    "ww_sw.to_pickle(spath+'ww_sw')\n",
    "\n",
    "#load in CSV for water withdrawals (separated by sufrace water or groundwater)\n",
    "queryName = 'water_withdrawals_irrig'\n",
    "ww_irrig = pd.read_csv(fpath+queryName+'.csv')  #read CSV\n",
    "#filter to remove column for region (just care about basin)\n",
    "ww_irrig = ww_irrig.groupby(['scenario','Units','subsector','year'])['value'].sum().reset_index()\n",
    "#these lines of code are used to clean up the basin name column (originally \"resource\") in the 3 dataframes\n",
    "ww_irrig[['crop','basin']] = ww_irrig['subsector'].str.split('_',n=2,expand=True)\n",
    "#save the cleaned up data as pickles:\n",
    "ww_irrig.to_pickle(spath+'ww_irrig')\n",
    "\n",
    "#load in maximum available runoff query output\n",
    "queryName = 'max_subresource'\n",
    "mr = pd.read_csv(fpath+queryName+'.csv') \n",
    "mr = mr[mr.subresource=='runoff'] #limit to just runoff (as opposed to all resources from the query)\n",
    "mr = mr.groupby(['scenario','Units','resource','year'])['value'].sum().reset_index()\n",
    "#clean up name to show basin instead of \"resource\"\n",
    "mr[['basin','ww']] = mr['resource'].str.split('_water withdrawals',n=2,expand=True)\n",
    "mr = mr.drop(['resource','ww'],axis=1)\n",
    "mr.to_pickle(spath+'mr')\n",
    "\n",
    "#water price\n",
    "queryName = 'water_price'\n",
    "wp = pd.read_csv(fpath+queryName+'.csv') \n",
    "#split up the name of the basin (take out _water withdrawals), make two columns basin and ww (ww is empty)\n",
    "wp[['basin','ww']] = wp['market'].str.split('_water withdrawals',n=2,expand=True)\n",
    "mktnames = wp.basin.unique() #list of market names\n",
    "bsnnames = [] #empty list to store basin names\n",
    "for mkt in mktnames: #loop through the markets\n",
    "    n = len(mkt) #length of string for market name\n",
    "    bsnnames.append(mkt[:int(n/2)]) #the basin name is half the length of the market name\n",
    "#make a dictionary for market names to basin names\n",
    "mkt_to_bsn = dict(zip(mktnames, bsnnames))\n",
    "#replace basin names to not be duplicated using the dictionary\n",
    "wp['basin'] = wp['basin'].map(mkt_to_bsn) #map the correct basin names\n",
    "#drop extra column\n",
    "wp = wp.drop(['ww'],axis=1)\n",
    "#save as pickle\n",
    "wp.to_pickle(spath+'wp')\n",
    "\n",
    "#save others as pickles too\n",
    "queryName = 'ag_production_allbasin_sum'\n",
    "agprod_sum = pd.read_csv(fpath+queryName+'.csv')\n",
    "agprod_sum.to_pickle(spath+'agprod_sum')\n",
    "queryName = 'land_alloc_sum'\n",
    "landalloc_sum = pd.read_csv(fpath+queryName+'.csv')\n",
    "landalloc_sum.to_pickle(spath+'landalloc_sum')\n",
    "queryName = 'land_alloc_indus'\n",
    "landalloc_indus = pd.read_csv(fpath+queryName+'.csv')\n",
    "landalloc_indus.to_pickle(spath+'landalloc_indus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gcam0",
   "language": "python",
   "name": "gcam0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
